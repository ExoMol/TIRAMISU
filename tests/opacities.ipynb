{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T20:27:46.215429Z",
     "start_time": "2025-03-24T20:27:44.454915Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# %%\n",
    "# %%\n",
    "import os\n",
    "import time\n",
    "import subprocess\n",
    "import pathlib\n",
    "import functools\n",
    "import math\n",
    "import numba\n",
    "import typing as t\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import astropy.units as u\n",
    "import astropy.constants as ac\n",
    "\n",
    "import pandas as pd\n",
    "from astropy import units as u\n",
    "from pathlib import Path\n",
    "from scipy.special import erf\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "_DEFAULT_CHUNK_SIZE = 10000000\n",
    "ac_h_c_on_kB = ac.h * ac.c.cgs / ac.k_B\n",
    "ac_16_pi_c = 8 * np.pi * ac.c.cgs\n",
    "const_h_c_on_kB = ac_h_c_on_kB.value\n",
    "const_16_pi_c = ac_16_pi_c.value\n",
    "\n",
    "# working_directory = r\"/scratch/cbowesman/OH/\"  # remote\n",
    "working_directory = r\"/mnt/c/PhD/OH/ExoMol/XABC11_Unbound_States_Trans/\"  # local\n",
    "\n",
    "\n",
    "log_file = fr\"{working_directory}OH_cont.log\"\n",
    "\n",
    "continuum_states_file = Path(fr\"{working_directory}16O-1H__MYTHOS.states.cont\")\n",
    "continuum_trans_files = Path(fr\"{working_directory}16O-1H__MYTHOS.trans.cont\")\n",
    "\n",
    "continuum_states = pd.read_csv(\n",
    "    continuum_states_file,\n",
    "    names=[\"id\", \"energy\", \"g\", \"J\"],\n",
    "    usecols=[0, 1, 2, 3],\n",
    "    sep=r\"\\s+\",\n",
    ")\n",
    "\n",
    "wn_grid = pd.read_csv(fr\"{working_directory}OH_T1_P1.0000e+03.xsec\", delimiter=r\"\\s+\", usecols=[0], names=[\"wn\"])\n",
    "wn_grid = wn_grid[\"wn\"].to_numpy()\n",
    "with open(log_file, \"a\") as file:\n",
    "    file.write(f\"Computing continuum absorption on wavenumber grid with {len(wn_grid)} points...\\n\")\n",
    "\n",
    "\n",
    "@numba.njit(parallel=True)\n",
    "def _continuum_band_profile_variable_width(\n",
    "    wn_grid: npt.NDArray[np.float64],\n",
    "    n_frac_i: npt.NDArray[np.float64],\n",
    "    a_fi: npt.NDArray[np.float64],\n",
    "    g_f: npt.NDArray[np.float64],\n",
    "    g_i: npt.NDArray[np.float64],\n",
    "    energy_fi: npt.NDArray[np.float64],\n",
    "    temperature: float,\n",
    "    cont_broad: npt.NDArray[np.float64],\n",
    ") -> npt.NDArray[np.float64]:\n",
    "    sqrtln2 = math.sqrt(math.log(2))\n",
    "    _abs_xsec = np.zeros(wn_grid.shape)\n",
    "    num_trans = energy_fi.shape[0]\n",
    "    num_grid = wn_grid.shape[0]\n",
    "\n",
    "    bin_widths = np.zeros(wn_grid.shape[0] + 1)\n",
    "    bin_widths[1:-1] = (wn_grid[:-1] + wn_grid[1:]) / 2.0 - wn_grid[:-1]\n",
    "\n",
    "    abs_coef = (\n",
    "        g_f\n",
    "        * n_frac_i\n",
    "        * a_fi\n",
    "        * (1 - np.exp(-const_h_c_on_kB * energy_fi / temperature))\n",
    "        / (const_16_pi_c * g_i * energy_fi**2)\n",
    "    )\n",
    "    sqrtln2_on_alpha = sqrtln2 / cont_broad\n",
    "\n",
    "    for i in numba.prange(num_trans):\n",
    "        for j in range(num_grid):\n",
    "            wn_shift = wn_grid[j] - energy_fi[i]\n",
    "            upper_width = bin_widths[j + 1]\n",
    "            lower_width = bin_widths[j]\n",
    "            if min(abs(wn_shift - lower_width), abs(wn_shift + upper_width)) <= 1500:\n",
    "                _abs_xsec[j] += (\n",
    "                    abs_coef[i]\n",
    "                    * (\n",
    "                        math.erf(sqrtln2_on_alpha[i] * (wn_shift + upper_width))\n",
    "                        - math.erf(sqrtln2_on_alpha[i] * (wn_shift - lower_width))\n",
    "                    )\n",
    "                    / (upper_width + lower_width)\n",
    "                )\n",
    "    # for i in numba.prange(num_trans):\n",
    "    #     start_idx = min(\n",
    "    #         np.argmax(abs(wn_grid - bin_widths[:-1] - energy_fi[i]) <= 1500),\n",
    "    #         np.argmax(abs(wn_grid + bin_widths[1:] - energy_fi[i]) <= 1500),\n",
    "    #     )\n",
    "    #     end_idx = len(wn_grid) - min(\n",
    "    #         np.argmax(abs(wn_grid - bin_widths[:-1] - energy_fi[i])[::-1] <= 1500),\n",
    "    #         np.argmax(abs(wn_grid + bin_widths[1:] - energy_fi[i])[::-1] <= 1500),\n",
    "    #     )\n",
    "    #     wn_shift = wn_grid[start_idx:end_idx] - energy_fi[i]\n",
    "    #     _abs_xsec[start_idx:end_idx] += (\n",
    "    #         abs_coef[i]\n",
    "    #         * (\n",
    "    #             erf(sqrtln2_on_alpha[i] * (wn_shift + bin_widths[start_idx + 1 : end_idx + 1]))\n",
    "    #             - erf(sqrtln2_on_alpha[i] * (wn_shift - bin_widths[start_idx:end_idx]))\n",
    "    #         )\n",
    "    #         / (bin_widths[start_idx + 1 : end_idx + 1] + bin_widths[start_idx:end_idx])\n",
    "    #     )\n",
    "    return _abs_xsec\n",
    "\n",
    "\n",
    "def boltzmann_population(states: pd.DataFrame, temperature: u.Quantity) -> pd.DataFrame:\n",
    "    states[\"q_lev\"] = states[\"g\"] * np.exp(-ac_h_c_on_kB * (states[\"energy\"] << 1 / u.cm) / temperature)\n",
    "    states[\"n\"] = states[\"q_lev\"] / states[\"q_lev\"].sum()\n",
    "    return states\n",
    "\n",
    "numba.set_num_threads(16)\n",
    "\n",
    "temperature_list = np.linspace(1, 4000, 40) << u.K\n",
    "\n",
    "for temperature in temperature_list:\n",
    "    cont_trans_reader = pd.read_csv(\n",
    "        continuum_trans_files,\n",
    "        names=[\"id_c\", \"id_i\", \"a_ci\", \"broad\"],\n",
    "        sep=r\"\\s+\",\n",
    "        chunksize=_DEFAULT_CHUNK_SIZE,\n",
    "    )\n",
    "    with open(log_file, \"a\") as file:\n",
    "        file.write(f\"Computing continuum absorption for T={temperature}...\\n\")\n",
    "    abs_xsec = np.zeros_like(wn_grid)\n",
    "    for chunk in cont_trans_reader:\n",
    "        temp_states = boltzmann_population(states=continuum_states.copy(), temperature=temperature)\n",
    "        chunk = chunk.merge(\n",
    "            temp_states[[\"id\", \"g\", \"energy\", \"n\"]],\n",
    "            left_on=\"id_i\",\n",
    "            right_on=\"id\",\n",
    "            how=\"inner\",\n",
    "        )\n",
    "        # chunk = chunk.loc[chunk[\"n_frac\"] > 0.0]  # Need to keep these for rates!\n",
    "        chunk = chunk.rename(\n",
    "            columns={\n",
    "                \"g\": \"g_i\",\n",
    "                \"energy\": \"energy_i\",\n",
    "                \"n\": \"n_i\",\n",
    "            }\n",
    "        )\n",
    "        chunk = chunk.drop(columns=[\"id_i\", \"id\"])\n",
    "\n",
    "        chunk = chunk.merge(\n",
    "            temp_states[[\"id\", \"g\", \"energy\"]],\n",
    "            left_on=\"id_c\",\n",
    "            right_on=\"id\",\n",
    "            how=\"inner\",\n",
    "        )\n",
    "        chunk = chunk.rename(columns={\"g\": \"g_c\", \"energy\": \"energy_c\"})\n",
    "        chunk = chunk.drop(columns=[\"id_c\", \"id\"])\n",
    "\n",
    "        chunk[\"energy_ci\"] = chunk[\"energy_c\"] - chunk[\"energy_i\"]\n",
    "        chunk = chunk.loc[\n",
    "            (chunk[\"energy_c\"] >= wn_grid[0])\n",
    "            & (chunk[\"energy_i\"] <= wn_grid[-1])  # TODO: IS this condition valid?\n",
    "            & (chunk[\"energy_ci\"] >= wn_grid[0])\n",
    "            & (chunk[\"energy_ci\"] <= wn_grid[-1])\n",
    "        ]\n",
    "        abs_xsec += _continuum_band_profile_variable_width(\n",
    "            wn_grid=wn_grid,\n",
    "            n_frac_i=chunk[\"n_i\"].to_numpy(),\n",
    "            a_fi=chunk[\"a_ci\"].to_numpy(),\n",
    "            g_f=chunk[\"g_c\"].to_numpy(),\n",
    "            g_i=chunk[\"g_i\"].to_numpy(),\n",
    "            energy_fi=chunk[\"energy_ci\"].to_numpy(),\n",
    "            temperature=temperature.value,\n",
    "            cont_broad=chunk[\"broad\"].to_numpy(),\n",
    "        )\n",
    "    np.savetxt(\n",
    "        fr\"{working_directory}OH_T{int(temperature.value)}.cont.xsec\",\n",
    "        np.array([wn_grid, abs_xsec]).T,\n",
    "        fmt=\"%17.8E\",\n",
    "    )\n",
    "    # Write out the profile for that T."
   ],
   "id": "523e54585bc95e66",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 44\u001B[0m\n\u001B[1;32m     35\u001B[0m continuum_trans_files \u001B[38;5;241m=\u001B[39m Path(\u001B[38;5;124mfr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mworking_directory\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m16O-1H__MYTHOS.trans.cont\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     37\u001B[0m continuum_states \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\n\u001B[1;32m     38\u001B[0m     continuum_states_file,\n\u001B[1;32m     39\u001B[0m     names\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mid\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124menergy\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mg\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mJ\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m     40\u001B[0m     usecols\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m3\u001B[39m],\n\u001B[1;32m     41\u001B[0m     sep\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124ms+\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     42\u001B[0m )\n\u001B[0;32m---> 44\u001B[0m wn_grid \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mfr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mworking_directory\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43mOH_T1_P1.0000e+03.xsec\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdelimiter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43ms+\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43musecols\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnames\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mwn\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     45\u001B[0m wn_grid \u001B[38;5;241m=\u001B[39m wn_grid[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwn\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mto_numpy()\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(log_file, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ma\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m file:\n",
      "File \u001B[0;32m~/venv/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[1;32m   1013\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m   1014\u001B[0m     dialect,\n\u001B[1;32m   1015\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1022\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[1;32m   1023\u001B[0m )\n\u001B[1;32m   1024\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m-> 1026\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/venv/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:626\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    623\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n\u001B[1;32m    625\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m parser:\n\u001B[0;32m--> 626\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mparser\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/venv/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1923\u001B[0m, in \u001B[0;36mTextFileReader.read\u001B[0;34m(self, nrows)\u001B[0m\n\u001B[1;32m   1916\u001B[0m nrows \u001B[38;5;241m=\u001B[39m validate_integer(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnrows\u001B[39m\u001B[38;5;124m\"\u001B[39m, nrows)\n\u001B[1;32m   1917\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1918\u001B[0m     \u001B[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001B[39;00m\n\u001B[1;32m   1919\u001B[0m     (\n\u001B[1;32m   1920\u001B[0m         index,\n\u001B[1;32m   1921\u001B[0m         columns,\n\u001B[1;32m   1922\u001B[0m         col_dict,\n\u001B[0;32m-> 1923\u001B[0m     ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[attr-defined]\u001B[39;49;00m\n\u001B[1;32m   1924\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnrows\u001B[49m\n\u001B[1;32m   1925\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1926\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m   1927\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[0;32m~/venv/3.12/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001B[0m, in \u001B[0;36mCParserWrapper.read\u001B[0;34m(self, nrows)\u001B[0m\n\u001B[1;32m    232\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    233\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlow_memory:\n\u001B[0;32m--> 234\u001B[0m         chunks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_reader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_low_memory\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    235\u001B[0m         \u001B[38;5;66;03m# destructive to chunks\u001B[39;00m\n\u001B[1;32m    236\u001B[0m         data \u001B[38;5;241m=\u001B[39m _concatenate_chunks(chunks)\n",
      "File \u001B[0;32mparsers.pyx:838\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mparsers.pyx:905\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._read_rows\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mparsers.pyx:874\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mparsers.pyx:891\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mparsers.pyx:2053\u001B[0m, in \u001B[0;36mpandas._libs.parsers.raise_parser_error\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m<frozen codecs>:331\u001B[0m, in \u001B[0;36mgetstate\u001B[0;34m(self)\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T13:20:51.459456Z",
     "start_time": "2025-03-17T13:20:07.966746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Add continuum Xsecs to outputs. The run \"run_trove_sup2.csh\" with the first launch line (which runs exocross) commented out to transform into pickles, stored in /xsec_combined/.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "cont_directory = r\"/scratch/dp060/dc-bowe4/exomolop/OH/\"  # Dial\n",
    "# cont_directory = r\"/mnt/c/PhD/OH/ExoMol/XABC11_Unbound_States_Trans/\"\n",
    "out_directory = r\"/scratch/dp060/dc-bowe4/exomolop/working/output/\"  # Dial\n",
    "# out_directory = r\"/mnt/c/PhD/OH/ExoCross/output/\"\n",
    "\n",
    "log_file = fr\"{cont_directory}OH_cont.log\"\n",
    "\n",
    "temperature_list = np.linspace(1, 4000, 40)\n",
    "for temperature in temperature_list:\n",
    "    cont_xsec = pd.read_csv(fr\"{cont_directory}OH_T{int(temperature)}.cont.xsec\", sep=r\"\\s+\", names=[\"wn\", \"intens\"])\n",
    "    # cont_xsec = pd.read_csv(fr\"{cont_directory}OH_T{int(temperature)}_P1.0000e+03.xsec\", sep=r\"\\s+\", names=[\"wn\", \"intens\"])\n",
    "    print(cont_xsec.head(4))\n",
    "    output_files = glob.glob(fr\"{out_directory}OH_T{int(temperature)}_P*.out\")\n",
    "    print(output_files)\n",
    "    for out_file in output_files:\n",
    "        out_xsec = pd.read_csv(out_file, sep=r\"\\s+\", names=[\"wn\", \"intens\"])\n",
    "        if len(out_xsec) != len(cont_xsec):\n",
    "            raise RuntimeError(f\"Xsec length mismatch for file {out_file}.\")\n",
    "        else:\n",
    "            out_xsec[\"intens\"] += cont_xsec[\"intens\"]\n",
    "        # print(out_xsec.to_numpy())\n",
    "        np.savetxt(\n",
    "            out_file,\n",
    "            out_xsec.to_numpy(),\n",
    "            fmt=\"%17.8E\",\n",
    "        )\n",
    "        with open(log_file, \"a\") as file:\n",
    "            file.write(f\"Processed {out_file}\\n\")"
   ],
   "id": "e803fb0221eec2f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         wn  intens\n",
      "0  1.000000     0.0\n",
      "1  1.000001     0.0\n",
      "2  1.000002     0.0\n",
      "3  1.000003     0.0\n",
      "['/mnt/c/PhD/OH/ExoCross/output/OH_T1_P1.0000e+03.out', '/mnt/c/PhD/OH/ExoCross/output/OH_T1_P1.0000e-08.out']\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T13:40:37.036292Z",
     "start_time": "2025-03-17T13:40:37.033468Z"
    }
   },
   "cell_type": "code",
   "source": "print([int(temp) for temp in np.linspace(1, 4000, 40)])",
   "id": "e878606bbe3e6059",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 103, 206, 308, 411, 513, 616, 718, 821, 923, 1026, 1128, 1231, 1334, 1436, 1539, 1641, 1744, 1846, 1949, 2051, 2154, 2256, 2359, 2461, 2564, 2667, 2769, 2872, 2974, 3077, 3179, 3282, 3384, 3487, 3589, 3692, 3794, 3897, 4000]\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6f84f2c7390d5727"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
